{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split # Импортируем функцию train_test_split для разделения данных на обучающий и тестовый наборы\n",
    "from scipy.stats import mstats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd #Импортируем pandas для удобства работы с данными\n",
    "import pickle #Импортируем библиотеку, которая сохраняет модель\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открытие датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C://Users//yegor//Desktop//datatech_internship//model//X_data.csv\",sep = \";\").rename(columns = {\"Unnamed: 0\":\"Date\"})\n",
    "y_train = pd.read_csv(\"C://Users//yegor//Desktop//datatech_internship//model//Y_train.csv\", sep=';', names=['Время забора пробы', 'Проба'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_columns = ['T_data_1_1', 'T_data_1_2', 'T_data_1_3', 'T_data_2_1', 'T_data_2_2', 'T_data_2_3',\n",
    "'T_data_3_1', 'T_data_3_2', 'T_data_3_3', 'T_data_4_1', 'T_data_4_2', 'T_data_4_3',\n",
    "'T_data_5_1', 'T_data_5_2', 'T_data_5_3', 'AH_data']\n",
    "\n",
    "for col in outlier_columns:\n",
    "    df_train[col] = mstats.winsorize(df_train[col], limits=[0.05, 0.05])\n",
    "\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'], format='%d.%m.%Y %H:%M')\n",
    "y_train['Время забора пробы'] = pd.to_datetime(y_train['Время забора пробы'], format='%d.%m.%Y %H:%M')\n",
    "\n",
    "\n",
    "# Объединение по условию совпадения дат\n",
    "merged_data = pd.merge(df_train, y_train, left_on='Date', right_on='Время забора пробы', how='inner')\n",
    "merged_data.drop(\"Время забора пробы\",axis = 1,inplace = True)\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], format='%d.%m.%Y %H:%M')\n",
    "\n",
    "# Создание новых признаков на основе колонки 'Date'\n",
    "merged_data['Year'] = merged_data['Date'].dt.year\n",
    "merged_data['Month'] = merged_data['Date'].dt.month\n",
    "merged_data['Day'] = merged_data['Date'].dt.day\n",
    "merged_data['Hour'] = merged_data['Date'].dt.hour\n",
    "merged_data['Minute'] = merged_data['Date'].dt.minute\n",
    "merged_data.drop(\"Date\",axis = 1,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_data.drop(['Проба'], axis=1)\n",
    "y = merged_data['Проба']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Применение StandardScaler к обучающему набору данных (fit_transform)\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "# Применение StandardScaler к тестовому набору данных (transform)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открытие обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C://Users//yegor//Desktop//datatech_internship//model//lr_reg.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация PFI\n",
    "\n",
    "**Permutation Feature Importance** — это метод оценки важности признаков в моделях машинного обучения. Он основан на идее, что если признак важен для предсказания, то его случайное перемешивание (перемешивание значений) должно значительно ухудшить производительность модели\n",
    "\n",
    "\n",
    "1. **Обучение модели**:\n",
    "- Сначала обучается модель на исходном наборе данных и вычисляется её производительность (например, точность, F1-меры и т.д.) на валидационном наборе.\n",
    "2. **Перемешивание признаков**:\n",
    "- Для каждого признака в наборе данных:\n",
    "- Признак перемешивается (перемешиваются значения этого признака в выборке), что разрушает связь между этим признаком и целевой переменной.\n",
    "\n",
    "3. **Вычисление важности**:\n",
    "- Важность признака определяется как разница между производительностью модели до и после перемешивания:\n",
    "$$\n",
    "\\text{Importance} = \\text{Performance}_{\\text{original}} - \\text{Performance}_{\\text{permuted}}\n",
    "$$\n",
    "\n",
    "\n",
    " - \\(\\text{Performance}_{\\text{original}}\\): Это метрика производительности модели (например, точность, F1-меры, AUC и т.д.), рассчитанная на исходном наборе данных, где все признаки находятся на своих местах. Это значение служит базовой линией для оценки важности признаков.\n",
    "- **\\(\\text{Performance}_{\\text{permuted}}\\)**: Это метрика производительности модели, рассчитанная на наборе данных, в котором значения одного или нескольких признаков были случайным образом перемешаны (перемешаны).\n",
    "\n",
    "\n",
    "- Чем больше разница, тем более важен признак для модели.\n",
    "5. **Повторение**:\n",
    "- Процесс повторяется несколько раз (обычно 10-30 раз) для получения более стабильной оценки важности, и затем вычисляется среднее значение и стандартное отклонение важности для каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_data_3_1: 0.219 (+/- 0.007)\n",
      "T_data_3_3: 0.178 (+/- 0.005)\n",
      "T_data_3_2: 0.175 (+/- 0.005)\n",
      "H_data: 0.052 (+/- 0.002)\n",
      "T_data_5_3: 0.020 (+/- 0.001)\n",
      "T_data_5_2: 0.012 (+/- 0.001)\n",
      "T_data_5_1: 0.012 (+/- 0.001)\n",
      "T_data_1_3: 0.010 (+/- 0.001)\n",
      "T_data_1_2: 0.009 (+/- 0.000)\n",
      "T_data_1_1: 0.006 (+/- 0.000)\n",
      "T_data_2_1: 0.004 (+/- 0.000)\n",
      "T_data_2_3: 0.004 (+/- 0.000)\n",
      "T_data_2_2: 0.002 (+/- 0.000)\n",
      "T_data_4_3: 0.000 (+/- 0.000)\n",
      "Minute: 0.000 (+/- 0.000)\n",
      "AH_data: -0.000 (+/- 0.000)\n",
      "T_data_4_2: -0.000 (+/- 0.000)\n",
      "Day: -0.000 (+/- 0.000)\n",
      "Hour: -0.000 (+/- 0.000)\n",
      "T_data_4_1: -0.000 (+/- 0.000)\n",
      "Year: -0.000 (+/- 0.000)\n",
      "Month: -0.000 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "std_errors = result.importances_std\n",
    "\n",
    "# Сортируем важности в убывающем порядке\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Выводим важности признаков\n",
    "feature_names = X.columns\n",
    "for f in range(X.shape[1]):\n",
    "    print(f\"{feature_names[sorted_indices[f]]}: {importances[sorted_indices[f]]:.3f} (+/- {std_errors[sorted_indices[f]]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Результаты анализа\n",
    "\n",
    "После выполнения кода были получены следующие результаты важности признаков (среднее значение и стандартная ошибка):\n",
    "\n",
    "1. **T_data_3_1**: 0.219 (+/- 0.007)\n",
    "2. **T_data_3_3**: 0.178 (+/- 0.005)\n",
    "3. **T_data_3_2**: 0.175 (+/- 0.005)\n",
    "4. **H_data**: 0.052 (+/- 0.002)\n",
    "5. **T_data_5_3**: 0.020 (+/- 0.001)\n",
    "6. **T_data_5_2**: 0.012 (+/- 0.001)\n",
    "7. **T_data_5_1**: 0.012 (+/- 0.001)\n",
    "8. **T_data_1_3**: 0.010 (+/- 0.001)\n",
    "9. **T_data_1_2**: 0.009 (+/- 0.000)\n",
    "10. **T_data_1_1**: 0.006 (+/- 0.000)\n",
    "11. **T_data_2_1**: 0.004 (+/- 0.000)\n",
    "12. **T_data_2_3**: 0.004 (+/- 0.000)\n",
    "13. **T_data_2_2**: 0.002 (+/- 0.000)\n",
    "14. **T_data_4_3**: 0.000 (+/- 0.000)\n",
    "15. **Minute**: 0.000 (+/- 0.000)\n",
    "16. **AH_data**: -0.000 (+/- 0.000)\n",
    "17. **T_data_4_2**: -0.000 (+/- 0.000)\n",
    "18. **Day**: -0.000 (+/- 0.000)\n",
    "19. **Hour**: -0.000 (+/- 0.000)\n",
    "20. **T_data_4_1**: -0.000 (+/- 0.000)\n",
    "21. **Year**: -0.000 (+/- 0.000)\n",
    "22. **Month**: -0.000 (+/- 0.000)\n",
    "\n",
    "#### Обсуждение результатов\n",
    "\n",
    "Из результатов видно, что температурные показатели в камерах (T_data_3_1, T_data_3_3, T_data_3_2) оказывают наибольшее влияние на предсказательную способность модели. Это может указывать на то, что температура является ключевым фактором в процессе, который моделируется.\n",
    "\n",
    "Высота слоя (H_data) также имеет значительную важность, что подчеркивает её роль в процессе. Влажность сырья (AH_data) и временные признаки (Minute, Day, Hour, Year, Month) показывают незначительное или отсутствующее влияние на модель, что может свидетельствовать о их меньшей роли в контексте рассматриваемого процесса.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
